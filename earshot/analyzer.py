import tensorflow as tf,numpy as np,pandas as pd,_pickle as pickle
import os, io, gc, json
import argparse, glob

from .phonology import are_cohorts, are_neighbors, are_rhymes
from .progressbar import progress

#with open('Hyper_Parameters.json', 'r') as f:
#    hp_Dict = json.load(f)

#if not hp_Dict['Device'] is None:
#    os.environ['CUDA_VISIBLE_DEVICES']= hp_Dict['Device']


class Analyzer:
    def __init__(self,analyzer_params,pattern_parameters):
        '''
        Class for taking checkpointed output of earshot and calculating model accuracy
        (as a function of epoch) and time-dependent accuracy, over pattern (model internal)
        time for all the checkpointed model output.
        '''
        self.analyzer_patterns = analyzer_patterns
        self.pattern_parametes = pattern_parameters
        # load/accumulate pattern information
        self.load_pattern_metadata()
        self.generate_category_dict()
        self.generate_adjusted_length_dict()
        # calculate accuracies, category (target/cohort/rhyme/unrelated)
        self.analyze()
        # these parse the files generated by self.analyze() and produce pickles
        #   with the summary data
        self.parse_rt_file()
        self.parse_cf_file()


    def load_pattern_metadata(self):
        '''
        Loads metadata info from pre-generated patterns made by patterns.PatternGenerator.
        '''
        with open(os.path.join(self.pattern_parameters.pattern_path, self.pattern_parameters.metadata_file).replace('\\', '/'), 'rb') as f:
            self.pattern_metadata = pickle.load(f)

        self.word_index = {word:index for index, (word,_) in enumerate(self.pattern_metadata['Target_Dict'].items()}
        self.step = {self.pattern_metadata['Word_and_Identifier_Dict'][path]: step for path,step in self.pattern_metadata['Step_Dict'].items()}
        self.max_step = max([step for step in self.step.values()])
        self.targets = np.array([self.pattern_metadata['Target_Dict'][word] for word, _ in sorted(list(self.word_index.items()), key = lambda x: x[1])]).astype(float32)


    def generate_category_dict(self):
        '''
        For each word, determines its cohorts, rhymes, DAS neighbors, and unrelated words from the
        pronunciation file.
        '''
        self.category_dict = {}
        for target_word,target_pron in self.pattern_metadata['Pronounciation_Dict'].items():
            self.category_dict[target_word,'Target'] = []
            self.category_dict[target_word,'Cohort'] = []
            self.category_dict[target_word,'Rhyme'] = []
            self.category_dict[target_word,'DAS_Neighborhood'] = []
            self.category_dict[target_word,'Unrelated'] = []

            for compare_word, compare_pron in self.pattern_metadata['Pronounciation_Dict'].items():
                compare_word_indx = self.word_index[compare_word]

                # assume word is unrelated by default
                if target_word == compare_word:
                    # word is the target; move on
                    self.category_dict[target_word, 'Target'].append(compare_word_indx)
                    continue

                # words cannot be both cohorts and rhymes
                if are_cohorts(target_pron, compare_pron):
                    # words are in the same cohort
                    self.category_dict[target_word, 'Cohort'].append(compare_word_indx)
                    # they may also be neighbors
                    if are_neighbors(target_pron,compare_pron):
                        self.category_dict[target_word, 'DAS_Neighborhood'].append(compare_word_indx)
                    continue
                elif are_rhymes(target_pron, compare_pron):
                    # words are rhymes and (by this def'n) automatically neighbors
                    self.category_dict[target_word, 'Rhyme'].append(compare_word_indx)
                    self.category_dict[target_word, 'DAS_Neighborhood'].append(compare_word_indx)
                    continue

                # words may be neighbors but not cohorts or rhymes
                if are_neighbors(target_pron,compare_pron):
                    self.category_dict[target_word, 'DAS_Neighborhood'].append(compare_word_indx)
                    continue

                # if we made it here, they must be unrelated
                self.category_dict[target_word, 'Unrelated'].append(compare_word_indx)


    def generate_adjusted_length_dict(self):
        '''
        This is used to establish uniqueness point, according to Heejo.
        '''
        self.adj_length_dict = {}

        for word,pron in self.pattern_metadata['Prononciation_Dict'].items():
            for cut_len in range(1,len(pron)+1):
                cut_pron = pron[:cut_len]
                to_compare = [candidate[:cut_len] for candidate in self.pattern_metadata['Pronunciation_Dict'].values() if pron != candidate]
                if not cut_pron in to_compare:
                    self.adj_length_dict[word] = cut_len - len(pron) - 1
                    break
            if not word in self.adj_length_dict:
                self.adj_length_dict[word] = 0


    def analysis(self):
        '''
        Reads checkpointed .pickle files in the appropriate results directory (set in the analyzer_parameters) to
        generate run summary information files (competitort activation, accuracy as a function of epoch).  Currently, all
        files reside in a "Test" subdirectory and have the format E_#.I_#.pickle.  This are the only files that will
        be analyzed.

        The run summary information text files could be removed and the pickles written directly; when I wrote the parsers,
        I didn't really understand this function.  If we were sure the parsers harvest everything we want, we could remove
        the intermediate txt files. (K.B. 10/22/20)
        '''
        result_files = glob.glob(os.path.join(self.analyzer_parameters.model_output_path, 'Test','E_*.pickle').replace('\\', '/')))
        # dictionaries that will be read into files
        reaction_times = ['\t'.join(['{}'.format(x) for x in ['Epoch','Word','Identifier','Pattern_Type','Pronunciation','Pronunciation_Length','Uniqueness_Point',
            'Cohort_N','Rhyme_N','Neighborhood_N','Onset_Absolute_RT','Onset_Relative_RT','Onset_Time_Dependent_RT','Offset_Absolute_RT','Offset_Relative_RT','Offset_Time_Dependent_RT']])]

        category_flows = ['\t'.join(['{}'.format(x) for x in ['Epoch','Word','Identifier','Pattern_Type','Pronunciation','Pronunciation_Length','Uniqueness_Point',
            'Cohort_N','Rhyme_N','Neighborhood_N','Category','Category_Count','Accuracy'] + list(range(self.max_Step))])]

        for f in result_files:
            result_dict = pickle.load(open(f,'rb'))
            epoch = result_dict['Epoch']
            info = result_dict['Info']
            outputs = result_dict['Result']

            for index, (output, (word,identfier,pattern_type)) in enumerate(zip(outputs,info)):
                data = self.generate_data(output, word, identifier) #[Num_Words, Steps]
                rt_dict = self.generate_rt(word, identifier, data)
                cf_dict = self.generate_category_flow(word, data)
                reaction_Times.append('\t'.join(['{}'.format(x) for x in [epoch,word,identifier,pattern_type,'.'.join(self.pattern_parameters.lexicon[word]),
                        len(self.pattern_parameters.lexicon[word]),self.adj_length_dict[word],len(self.category_dict[word, 'Cohort']),len(self.category_dict[word, 'Rhyme']),
                        len(self.category_dict[word, 'DAS_Neighborhood']),rt_dict['Onset', 'Absolute'],rt_Dict['Onset', 'Relative'],rt_Dict['Onset', 'Time_Dependent'],
                        rt_Dict['Offset', 'Absolute'],rt_Dict['Offset', 'Relative'],rt_Dict['Offset', 'Time_Dependent']]]))

                for category in ["Target", "Cohort", "Rhyme", "Unrelated", "Other_Max"]:
                    if category == "Other_Max":
                        category_count = np.nan
                    else:
                        category_count = len(self.category_dict[word, category])
                    category_Flows.append('\t'.join(['{}'.format(x) for x in [epoch,word,identifier,pattern_type,'.'.join(self.pattern_parameters.lexicon[word]),
                        len(self.pattern_parameters.lexicon[word]),self.adj_length_dict[word],len(self.category_dict[word, 'Cohort']),len(self.category_dict[word, 'Rhyme']),
                        len(self.category_dict[word, 'DAS_Neighborhood']),category,category_count,not np.isnan(rt_dict["Onset", "Time_Dependent"])]
                        + ['{:.5f}'.format(x) for x in cf_dict[category]]]))

                progress(index + 1,outputs.shape[0],status=f)
            print()
        # these files could be removed if we were sure the parse_ functions harvest everything we want
        with open(os.path.join(self.result_Path, 'Test', 'RTs.txt').replace('\\', '/'), 'w') as f:
                f.write('\n'.join(reaction_Times))
        with open(os.path.join(self.result_Path, 'Test', 'Category_Flows.txt').replace('\\', '/'), 'w') as f:
                f.write('\n'.join(category_Flows))


    def generate_data(self, output, word, identifier):
        '''
        Heejo says: Data generation is progressed pattern by pattern, not multiple pattern because GPU consuming.
        output: [Steps, Dims]

        N.B. generate_data() is a terrible name for this function.  I think this just stacks up single calculations of
        cosine similarity from calculate_data? (K.B.)
        '''
        cs_list = []
        for batch_index in range(0, output.shape[1], self.analyzer_parameters.batch_step:
            cs_list.append(self.calculate_data(output= output[batch_index:batch_index + self.analyzer_parameters.batch_step]))
        cos_sim = np.hstack(cs_list)
        if self.analyzer_parameters.step_cut:
            cos_sim[:, self.step[word, identifier]:] = cos_sim[:, [self.step[word, identifier] - 1]]
        return cos_sim


    @tf.function
    def self.calculate_data(self,outputs):
        '''
        This actually computes cosines.

        Heejo says:
                output: [Steps, Dims]
                self.targets: [Num_Words, Dims]
        '''
        output = tf.convert_to_tensor(output, dtype=tf.float32)
        targets = tf.convert_to_tensor(self.targets, dtype=tf.float32)

        #Heejo: [Num_Words, Steps, Dims], increase dimension and tiled for 2D comparing.
        tiled_output = tf.tile(tf.expand_dims(output, [0]),multiples = [tf.shape(targets)[0], 1, 1])
        # Heejo: [Num_Words, Steps, Dims], increase dimension and tiled for 2D comparing.
        tiled_targets = tf.tile(tf.expand_dims(targets, [1]),multiples = [1, tf.shape(output)[0], 1])
        # do the calculation
        ttto = tiled_targets*tiled_output
        ttsq = tf.pow(tiled_targets,2)
        tosq = tf.pow(tiled_output,2)
        cos_sim = tf.reduce_sum(ttto, axis = 2)/(tf.sqrt(tf.reduce_sum(ttsq, axis = 2)) * tf.sqrt(tf.reduce_sum(tosq, axis = 2)) + 1e-7)  #[Num_Words, Steps]

        return cos_sim


    def generate_rt(self, word, identifier, data):
        '''
        Operationalizes accuracy using three different definitions and the cutoff parameters supplied
        in the analyzer options.

        absolute accuracy:
            point at which the most active word crosses the absolute activity threshold

        relative accuracy:
            point at which the activity of the most active word exceeds the next most active word by the
            relative threshold

        time-dependent accuracy:
            activity of the most active word has to be greater than the activity of the next most
            active word by a threshold and maintain that difference for a given number of time steps
        '''
        rt_dict = {('Onset', 'Absolute'): np.nan,('Onset', 'Relative'): np.nan,('Onset', 'Time_Dependent'): np.nan}

        target_index = self.word_index[word]
        target_array = data[target_index]
        # this is the runner up word (after the target)
        other_max_array = np.max(np.delete(data, target_index, 0), axis=0)

        # makes for less typing
        abs_cut = self.analyzer_parameters.abs_acc_crit
        rel_delta = self.analyzer_parameters.rel_acc_crit
        td_cut = self.analyzer_parameters.td_acc_crit[1]
        td_T = self.analyzer_parameters.td_acc_crit[0]

        # absolute RT
        if not (other_max_array > abs_cut).any():
            abs_check_array = target_array > abs_cut
            for step in range(self.max_step):
                if abs_check_array[step]:
                    rt_dict['Onset', 'Absolute'] = step
                    break
        # Calculate Offset RT
        if not np.isnan(rt_dict['Onset', 'Absolute']):
            rt_dict['Offset', 'Absolute'] = rt_dict['Onset', 'Absolute'] - self.step[word, identifier]
        else:
            rt_dict['Offset', 'Absolute'] = np.nan

        #relative RT
        rel_check_array = target_array > (other_max_array + rel_delta)
        for step in range(self.max_step):
            if relative_check_array[step]:
                rt_dict['Onset', 'Relative'] = step
                break
        # Calculate Offset RT
        if not np.isnan(rt_dict['Onset', 'Relative']):
            rt_dict['Offset', 'Relative'] = rt_dict['Onset', 'Relative'] - self.step[word, identifier]
        else:
            rt_dict['Offset', 'Relative'] = np.nan

        # time-dependent RT
        td_check_array_crit = target_array > other_max_array + td_cut
        td_check_array_sus = target_array > other_max_array
        for step in range(self.max_Step - td_T):
            if all(np.hstack([td_check_array_crit[step:step + td_T],td_check_array_sus[step + td_T:]])):
                rt_Dict['Onset', 'Time_Dependent'] = step
                break
        # Calculate Offset RT
        if not np.isnan(rt_dict['Onset', 'Time_Dependent']):
            rt_dict['Offset', 'Time_Dependent'] = rt_dict['Onset', 'Time_Dependent'] - self.step_Dict[word, identifier]
        else:
            rt_dict['Offset', 'Time_Dependent'] = np.nan

        return rt_dict


    def parse_rt_file(self):
        '''
        Reads the "RTs.txt" file produced by EARShot and creates an Epoch-Accuracy
        dictionary for onset- and off-set relative, absolute, and time-dependent
        accuracies. Saves the result to a pickle.
        '''
        acc_file = os.path.join(self.analyzer_patterns.model_output_path, 'Test', 'RTs.txt').replace('\\', '/')
        data = pd.read_csv(acc_file,sep='\t')
        # dictionary to hold the results
        acc_data = {}.fromkeys(data.columns[10:].values)
        epochs = list(np.unique(data["Epoch"]))
        for meas in acc_data:
            acc_data[meas] = {}.fromkeys(np.unique(data["Epoch"]))

        for e in epochs:
            subframe = data[data["Epoch"] == e]
            for meas in acc_data:
                n_wrong = subframe[meas].isnull().sum()
                n_total = len(subframe[meas])
                acc_data[meas][e] = (n_total - n_wrong)/n_total

        # dump the results
        fname = os.path.join(self.result_Path, 'Test', 'ACC.pydb').replace('\\', '/')
        pickle.dump(acc_data,open(fname,'wb'))


    def parse_cf_file(self):
        '''
        Reads the "Category_Flows.txt" file produced by EARShot and creates average
        similarities over (recurrent model) time to target, cohort, rhymes, and
        unrelated words in the lexicon, for each checkpointed epoch.

        I'm not handling speakers/word/etc. at all right now - this just
        averages over every correct target response in every epoch.

        Saves the resulting dictionary to a pickle.
        '''
        cf_file = os.path.join(self.analyzer_patterns.model_output_path, 'Test', 'Category_Flows.txt').replace('\\', '/')
        data = pd.read_csv(cf_file,sep='\t')

        # set up the dictionary to hold the results
        cat_data = {}.fromkeys(np.unique(data["Epoch"]))
        # there's nothing useful in the zero-epoch set
        cat_data.pop(0)
        for e in cat_data:
            cat_data[e] = {}.fromkeys(np.unique(data["Category"]))

        # now accumulate stats for all epochs > 0; ignore any incorrect responses
        for e in cat_data:
            epoch = data[(data["Epoch"] == e) & (data["Accuracy"] == True)]
            # appropriate selections
            for c in cat_data[e]:
                mean_series = epoch[epoch['Category'] == c].mean()
                cat_data[e][c] = mean_series.values[13:]

        # now dump the results
        fname = os.path.join(self.result_Path, 'Test', 'CS.pydb').replace('\\', '/')
        pickle.dump(cat_data,open('fname','wb'))


class Analyzer:
    def __init__(self,path,
        self,
        path,
        absolute_Criterion= 0.7,
        relative_Criterion= 0.05,
        time_Dependency_Criterion= (10, 0.05),
        step_Cut= True
        ):
        self.result_Path = os.path.join(hp_Dict['Result_Path'], path).replace('\\', '/')

        self.absolute_Criterion = absolute_Criterion
        self.relative_Criterion = relative_Criterion
        self.time_Dependency_Criterion = time_Dependency_Criterion
        self.step_Cut = step_Cut

        self.Pattern_Metadata_Load()    # self.word_Index_Dict, self.step_Dict, self.max_Step, self.targets
        self.Category_Dict_Generate()   # self.category_Dict
        self.Adjusted_Length_Dict_Generate()    # self.adjusted_Length_Dict

        self.Analysis()

        self.parse_rt_file()
        self.parse_cf_file()


    def parse_rt_file(self):
        '''
        Reads the "RTs" file produced by EARShot and creates an Epoch-Accuracy
        dictionary for onset- and off-set relative, absolute, and time-dependent
        accuracies. Saves the result to a pickle.
        '''
        acc_file = os.path.join(self.result_Path, 'Test', 'RTs.txt').replace('\\', '/')
        data = pd.read_csv(acc_file,sep='\t')
        # dictionary to hold the results
        acc_data = {}.fromkeys(data.columns[10:].values)
        epochs = list(np.unique(data["Epoch"]))
        for meas in acc_data:
            acc_data[meas] = {}.fromkeys(np.unique(data["Epoch"]))

        for e in epochs:
            subframe = data[data["Epoch"] == e]
            for meas in acc_data:
                n_wrong = subframe[meas].isnull().sum()
                n_total = len(subframe[meas])
                acc_data[meas][e] = (n_total - n_wrong)/n_total

        # dump the results
        fname = os.path.join(self.result_Path, 'Test', 'ACC.pydb').replace('\\', '/')
        pickle.dump(acc_data,open(fname,'wb'))


    def parse_cf_file(self):
        '''
        Reads the "Category_Flows" file produced by EARShot and creates average
        similarities over (recurrent model) time to target, cohort, rhymes, and
        unrelated words in the lexicon, for each checkpointed epoch.

        I'm not handling speakers/word/etc. at all right now - this just
        averages over every correct target response in every epoch.

        Saves the resulting dictionary to a pickle.
        '''
        cf_file = os.path.join(self.result_Path, 'Test', 'Category_Flows.txt').replace('\\', '/')
        data = pd.read_csv(cf_file,sep='\t')

        # set up the dictionary to hold the results
        cat_data = {}.fromkeys(np.unique(data["Epoch"]))
        # there's nothing useful in the zero-epoch set
        cat_data.pop(0)
        for e in cat_data:
            cat_data[e] = {}.fromkeys(np.unique(data["Category"]))

        # now accumulate stats for all epochs > 0; ignore any incorrect responses
        for e in cat_data:
            epoch = data[(data["Epoch"] == e) & (data["Accuracy"] == True)]
            # appropriate selections
            for c in cat_data[e]:
                mean_series = epoch[epoch['Category'] == c].mean()
                cat_data[e][c] = mean_series.values[13:]

        # now dump the results
        fname = os.path.join(self.result_Path, 'Test', 'CS.pydb').replace('\\', '/')
        pickle.dump(cat_data,open('fname','wb'))


    def Analysis(self, batch_Steps= 200):
        result_File_List = sorted([ #Result files sorting
            os.path.join(self.result_Path, 'Test', x).replace('\\', '/')
            for x in os.listdir(os.path.join(self.result_Path, 'Test').replace('\\', '/'))
            if x.endswith('.pickle') and x != 'Metadata.pickle'
            ])

        reaction_Times = [
            '\t'.join(['{}'.format(x) for x in [
                'Epoch',
                'Word',
                'Identifier',
                'Pattern_Type',
                'Pronunciation',
                'Pronunciation_Length',
                'Uniqueness_Point',
                'Cohort_N',
                'Rhyme_N',
                'Neighborhood_N',
                'Onset_Absolute_RT',
                'Onset_Relative_RT',
                'Onset_Time_Dependent_RT',
                'Offset_Absolute_RT',
                'Offset_Relative_RT',
                'Offset_Time_Dependent_RT'
            ]])]
        category_Flows = [
            '\t'.join(['{}'.format(x) for x in [
                'Epoch',
                'Word',
                'Identifier',
                'Pattern_Type',
                'Pronunciation',
                'Pronunciation_Length',
                'Uniqueness_Point',
                'Cohort_N',
                'Rhyme_N',
                'Neighborhood_N',
                'Category',
                'Category_Count',
                'Accuracy'
            ] + list(range(self.max_Step))])]
        for result_File in result_File_List:
            with open(result_File, 'rb') as f:
                result_Dict = pickle.load(f)
            epoch = result_Dict['Epoch']
            infos = result_Dict['Info']
            outputs = result_Dict['Result'] #[Batch, Steps, Dims]

            for index, (output, (word, identifier, pattern_Type)) in enumerate(zip(outputs, infos)):
                data = self.Data_Generate(output, word, identifier, batch_Steps) #[Num_Words, Steps]
                rt_Dict = self.RT_Generate(word, identifier, data)
                category_Flow_Dict = self.Category_Flow_Generate(word, data)
                reaction_Times.append(
                    '\t'.join(['{}'.format(x) for x in [
                        epoch,
                        word,
                        identifier,
                        pattern_Type,
                        '.'.join(self.pattern_Metadata_Dict['Pronunciation_Dict'][word]),
                        len(self.pattern_Metadata_Dict['Pronunciation_Dict'][word]),
                        self.adjusted_Length_Dict[word],
                        len(self.category_Dict[word, 'Cohort']),
                        len(self.category_Dict[word, 'Rhyme']),
                        len(self.category_Dict[word, 'DAS_Neighborhood']),
                        rt_Dict['Onset', 'Absolute'],
                        rt_Dict['Onset', 'Relative'],
                        rt_Dict['Onset', 'Time_Dependent'],
                        rt_Dict['Offset', 'Absolute'],
                        rt_Dict['Offset', 'Relative'],
                        rt_Dict['Offset', 'Time_Dependent']
                        ]])
                    )

                for category in ["Target", "Cohort", "Rhyme", "Unrelated", "Other_Max"]:
                    if category == "Other_Max":
                        category_Count = np.nan
                    else:
                        category_Count = len(self.category_Dict[word, category])
                    category_Flows.append(
                        '\t'.join(['{}'.format(x) for x in [
                            epoch,
                            word,
                            identifier,
                            pattern_Type,
                            '.'.join(self.pattern_Metadata_Dict['Pronunciation_Dict'][word]),
                            len(self.pattern_Metadata_Dict['Pronunciation_Dict'][word]),
                            self.adjusted_Length_Dict[word],
                            len(self.category_Dict[word, 'Cohort']),
                            len(self.category_Dict[word, 'Rhyme']),
                            len(self.category_Dict[word, 'DAS_Neighborhood']),
                            category,
                            category_Count,
                            not np.isnan(rt_Dict["Onset", "Time_Dependent"])
                            ] + ['{:.5f}'.format(x) for x in category_Flow_Dict[category]]])
                        )

                progress(
                    index + 1,
                    outputs.shape[0],
                    status= result_File
                    )
            print()

        with open(os.path.join(self.result_Path, 'Test', 'RTs.txt').replace('\\', '/'), 'w') as f:
            f.write('\n'.join(reaction_Times))
        with open(os.path.join(self.result_Path, 'Test', 'Category_Flows.txt').replace('\\', '/'), 'w') as f:
            f.write('\n'.join(category_Flows))


    def Data_Generate(self, output, word, identifier, batch_Steps= 200):
        '''
        Data generation is progressed pattern by pattern, not multiple pattern because GPU consuming.
        output: [Steps, Dims]
        '''
        cs_List = []
        for batch_Index in range(0, output.shape[1], batch_Steps):
            cs_List.append(self.Data_Calc(output= output[batch_Index:batch_Index + batch_Steps]))
        cosine_Similarity = np.hstack(cs_List)
        if self.step_Cut:
            cosine_Similarity[:, self.step_Dict[word, identifier]:] = cosine_Similarity[:, [self.step_Dict[word, identifier] - 1]]

        return cosine_Similarity

    @tf.function
    def Data_Calc(self, output):
        '''
        output: [Steps, Dims]
        self.targets: [Num_Words, Dims]
        '''
        output = tf.convert_to_tensor(output, dtype= tf.float32)
        targets = tf.convert_to_tensor(self.targets, dtype= tf.float32)

        tiled_Output = tf.tile(
            tf.expand_dims(output, [0]),
            multiples = [tf.shape(targets)[0], 1, 1]
            )   #[Num_Words, Steps, Dims], increase dimension and tiled for 2D comparing.
        tiled_Targets = tf.tile(
            tf.expand_dims(targets, [1]),
            multiples = [1, tf.shape(output)[0], 1]
            )   #[Num_Words, Steps, Dims], increase dimension and tiled for 2D comparing.
        cosine_Similarity = \
            tf.reduce_sum(tiled_Targets * tiled_Output, axis = 2) / \
            (
                tf.sqrt(tf.reduce_sum(tf.pow(tiled_Targets, 2), axis = 2)) * \
                tf.sqrt(tf.reduce_sum(tf.pow(tiled_Output, 2), axis = 2)) + \
                1e-7
                )  #[Num_Words, Steps]

        return cosine_Similarity

    def RT_Generate(self, word, identifier, data):
        rt_Dict = {
            ('Onset', 'Absolute'): np.nan,
            ('Onset', 'Relative'): np.nan,
            ('Onset', 'Time_Dependent'): np.nan
            }

        target_Index = self.word_Index_Dict[word]
        target_Array = data[target_Index]
        other_Max_Array = np.max(np.delete(data, target_Index, 0), axis=0)  #Target is removed, and using the max value of each time step.

        #Absolute threshold RT
        if not (other_Max_Array > self.absolute_Criterion).any():
            absolute_Check_Array = target_Array > self.absolute_Criterion
            for step in range(self.max_Step):
                if absolute_Check_Array[step]:
                    rt_Dict['Onset', 'Absolute'] = step
                    break

        #Relative threshold RT
        relative_Check_Array = target_Array > (other_Max_Array + self.relative_Criterion)
        for step in range(self.max_Step):
            if relative_Check_Array[step]:
                rt_Dict['Onset', 'Relative'] = step
                break

        #Time dependent RT
        time_Dependency_Check_Array_with_Criterion = target_Array > other_Max_Array + self.time_Dependency_Criterion[1]
        time_Dependency_Check_Array_Sustainment = target_Array > other_Max_Array
        for step in range(self.max_Step - self.time_Dependency_Criterion[0]):
            if all(np.hstack([
                time_Dependency_Check_Array_with_Criterion[step:step + self.time_Dependency_Criterion[0]],
                time_Dependency_Check_Array_Sustainment[step + self.time_Dependency_Criterion[0]:]
                ])):
                rt_Dict['Onset', 'Time_Dependent'] = step
                break

        #Offset_RT = Onset_RT - length
        if not np.isnan(rt_Dict['Onset', 'Absolute']):
            rt_Dict['Offset', 'Absolute'] = rt_Dict['Onset', 'Absolute'] - self.step_Dict[word, identifier]
        else:
            rt_Dict['Offset', 'Absolute'] = rt_Dict['Onset', 'Absolute']    #np.nan
        if not np.isnan(rt_Dict['Onset', 'Relative']):
            rt_Dict['Offset', 'Relative'] = rt_Dict['Onset', 'Relative'] - self.step_Dict[word, identifier]
        else:
            rt_Dict['Offset', 'Relative'] = rt_Dict['Onset', 'Relative']    #np.nan
        if not np.isnan(rt_Dict['Onset', 'Time_Dependent']):
            rt_Dict['Offset', 'Time_Dependent'] = rt_Dict['Onset', 'Time_Dependent'] - self.step_Dict[word, identifier]
        else:
            rt_Dict['Offset', 'Time_Dependent'] = rt_Dict['Onset', 'Time_Dependent']    #np.nan

        return rt_Dict

    def Category_Flow_Generate(self, word, data):   #For categorized flow
        category_Flow_Dict = {}

        for category in ['Target', 'Cohort', 'Rhyme', 'Unrelated']:
            if len(self.category_Dict[word, category]) > 0:
                category_Flow_Dict[category] = np.mean(data[self.category_Dict[word, category],:], axis=0) #Calculation mean of several same category flows.
            else:
                category_Flow_Dict[category] = np.zeros((data.shape[1])) * np.nan   # If there is no word which is belonged a specific category, nan value.

        category_Flow_Dict['All'] = np.mean(data, axis=0)
        category_Flow_Dict['Other_Max'] = np.max(np.delete(data, self.word_Index_Dict[word], 0), axis=0)   #Target is removed, and using the max value of each time step.

        return category_Flow_Dict


    def Pattern_Metadata_Load(self):
        with open(os.path.join(hp_Dict['Pattern']['Pattern_Path'], hp_Dict['Pattern']['Metadata_File']).replace('\\', '/'), 'rb') as f:
            self.pattern_Metadata_Dict = pickle.load(f)

        self.word_Index_Dict = {
            word: index
            for index, (word, _) in enumerate(self.pattern_Metadata_Dict['Target_Dict'].items())
            }

        self.step_Dict = {
            self.pattern_Metadata_Dict['Word_and_Identifier_Dict'][path]: step
            for path, step in self.pattern_Metadata_Dict['Step_Dict'].items()
            }
        self.max_Step = max([step for step in self.step_Dict.values()])

        self.targets = np.array([
            self.pattern_Metadata_Dict['Target_Dict'][word]
            for word, _ in sorted(list(self.word_Index_Dict.items()), key= lambda x: x[1])
            ]).astype(np.float32)

    def Category_Dict_Generate(self):
        self.category_Dict = {}
        for target_Word, target_Pronunciation in self.pattern_Metadata_Dict['Pronunciation_Dict'].items():
            self.category_Dict[target_Word, 'Target'] = []
            self.category_Dict[target_Word, 'Cohort'] = []
            self.category_Dict[target_Word, 'Rhyme'] = []
            self.category_Dict[target_Word, 'DAS_Neighborhood'] = []
            self.category_Dict[target_Word, 'Unrelated'] = []

            for compare_Word, compare_Pronunciation in self.pattern_Metadata_Dict['Pronunciation_Dict'].items():
                compare_Word_Index = self.word_Index_Dict[compare_Word]

                unrelated = True

                if target_Word == compare_Word:
                    self.category_Dict[target_Word, 'Target'].append(compare_Word_Index)
                    unrelated = False
                if target_Pronunciation[0:2] == compare_Pronunciation[0:2] and target_Word != compare_Word: #Cohort
                    self.category_Dict[target_Word, 'Cohort'].append(compare_Word_Index)
                    unrelated = False
                if target_Pronunciation[1:] == compare_Pronunciation[1:] and target_Pronunciation[0] != compare_Pronunciation[0] and target_Word != compare_Word:   #Rhyme
                    self.category_Dict[target_Word, 'Rhyme'].append(compare_Word_Index)
                    unrelated = False
                if unrelated:
                    self.category_Dict[target_Word, 'Unrelated'].append(compare_Word_Index)  #Unrelated
                #For test
                if self.DAS_Neighborhood_Checker(target_Pronunciation, compare_Pronunciation):   #Neighborhood
                    self.category_Dict[target_Word, 'DAS_Neighborhood'].append(compare_Word_Index)

    def DAS_Neighborhood_Checker(self, pronunciation1, pronunciation2):   #Delete, Addition, Substitution neighborhood checking
        #Same pronunciation
        if pronunciation1 == pronunciation2:
            return False

        #Exceed range
        elif abs(len(pronunciation1) - len(pronunciation2)) > 1:    #The length difference is bigger than 1, two pronunciations are not related.
            return False

        #Deletion
        elif len(pronunciation1) == len(pronunciation2) + 1:
            for index in range(len(pronunciation1)):
                deletion = pronunciation1[:index] + pronunciation1[index + 1:]
                if deletion == pronunciation2:
                    return True

        #Addition
        elif len(pronunciation1) == len(pronunciation2) - 1:
            for index in range(len(pronunciation2)):
                deletion = pronunciation2[:index] + pronunciation2[index + 1:]
                if deletion == pronunciation1:
                    return True

        #Substitution
        elif len(pronunciation1) == len(pronunciation2):
            for index in range(len(pronunciation1)):
                pronunciation1_Substitution = pronunciation1[:index] + pronunciation1[index + 1:]
                pronunciation2_Substitution = pronunciation2[:index] + pronunciation2[index + 1:]
                if pronunciation1_Substitution == pronunciation2_Substitution:
                    return True

        return False

    def Adjusted_Length_Dict_Generate(self): #For uniqueness point.
        self.adjusted_Length_Dict = {}

        for word, pronunciation in self.pattern_Metadata_Dict['Pronunciation_Dict'].items():
            for cut_Length in range(1, len(pronunciation) + 1):
                cut_Pronunciation = pronunciation[:cut_Length]
                cut_Comparer_List = [comparer[:cut_Length] for comparer in self.pattern_Metadata_Dict['Pronunciation_Dict'].values() if pronunciation != comparer]
                if not cut_Pronunciation in cut_Comparer_List:  #When you see a part of target phoneme string, if there is no other competitor.
                    self.adjusted_Length_Dict[word] = cut_Length - len(pronunciation) - 1
                    break
            if not word in self.adjusted_Length_Dict.keys():
                self.adjusted_Length_Dict[word] = 0


if __name__ == '__main__':
    argParser = argparse.ArgumentParser()
    argParser.add_argument('-d', '--directory', default= '', type= str)
    argParser.add_argument('-a', '--absolute', default= 0.7, type= float)
    argParser.add_argument('-r', '--relative', default= 0.05, type= float)
    argParser.add_argument('-tw', '--time_dependency_width', default= 10, type= float)
    argParser.add_argument('-th', '--time_dependency_height', default= 0.05, type= float)
    argument_Dict = vars(argParser.parse_args())

    new_Analyzer = Analyzer(
        path= argument_Dict['directory'],
        absolute_Criterion= argument_Dict['absolute'],
        relative_Criterion= argument_Dict['relative'],
        time_Dependency_Criterion= (
            argument_Dict['time_dependency_width'],
            argument_Dict['time_dependency_height']
            ),
        step_Cut= True
        )
